// Services/STTService.swift
import Foundation
import SwiftUI
import Combine
import AVFoundation
import WhisperKit

@MainActor
class STTService: ObservableObject {
    @Published var isModelLoading = true
    @Published var statusMessage = "æº–å‚™è¼‰å…¥ AI æ¨¡å‹..."
    
    private var pipe: WhisperKit?
    private var audioRecorder: AVAudioRecorder?
    private var audioFilename: URL?
    
    init() {
        setupAudioSession()
        Task {
            do {
                self.statusMessage = "ä¸‹è¼‰ Whisper æ¨¡å‹ä¸­..."
                // ä¸‹è¼‰ä¸¦è¼‰å…¥ Base æ¨¡å‹
                pipe = try await WhisperKit(model: "distil-large-v3", download: true)
                self.isModelLoading = false
                self.statusMessage = "Whisper æ¨¡å‹å°±ç·’"
                print("âœ… Whisper æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            } catch {
                print("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: \(error)")
                self.statusMessage = "æ¨¡å‹è¼‰å…¥å¤±æ•—"
            }
        }
    }
    
    private func setupAudioSession() {
        do {
            let session = AVAudioSession.sharedInstance()
            // ä¿®æ­£é»ƒè‰²è­¦å‘Šï¼šä½¿ç”¨å®Œæ•´å¯«æ³•
            try session.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
            try session.setActive(true)
        } catch {
            print("âŒ Audio Session è¨­å®šå¤±æ•—: \(error)")
        }
    }
    
    func startRecording() {
        let docPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        audioFilename = docPath.appendingPathComponent("akka_input.wav")
        
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatLinearPCM),
            AVSampleRateKey: 16000,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        do {
            audioRecorder = try AVAudioRecorder(url: audioFilename!, settings: settings)
            audioRecorder?.record()
            print("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³...")
        } catch {
            print("âŒ éŒ„éŸ³å•Ÿå‹•å¤±æ•—: \(error)")
        }
    }
    
    // ç§»é™¤ Prompt åƒæ•¸ï¼Œå›æ­¸å–®ç´”è¾¨è­˜
    func stopAndTranscribe() async -> String? {
        audioRecorder?.stop()
        audioRecorder = nil
        
        guard let pipe = pipe, let audioURL = audioFilename else {
            print("âš ï¸ æ¨¡å‹æœªå°±ç·’æˆ–ç„¡éŸ³æª”")
            return nil
        }
        
        print("ğŸ§  é–‹å§‹è¾¨è­˜ (Whisper On-Device)...")
        
        do {
            // ä½¿ç”¨æœ€åŸºæœ¬çš„è§£ç¢¼é¸é … (æš«æ™‚ç§»é™¤ Prompt Injection)
            let options = DecodingOptions(language: "zh")
            
            let result = try await pipe.transcribe(
                audioPath: audioURL.path,
                decodeOptions: options
            )
            
            let text = result.first?.text ?? ""
            print("ğŸ“ è¾¨è­˜çµæœ: \(text)")
            
            // ä¿®æ­£ç´…å­—ï¼šæ˜ç¢ºä½¿ç”¨ CharacterSet
            return text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
            
        } catch {
            print("âŒ è¾¨è­˜å¤±æ•—: \(error)")
            return nil
        }
    }
}
