import Foundation
import AVFoundation
import WhisperKit
import Combine

// MARK: - æ¨¡å‹å®šç¾©
enum WhisperModel: String, CaseIterable, Identifiable {
    // ğŸ”¥ å”¯ä¸€æ¨è–¦ï¼šOpenAI å®˜æ–¹ Turbo é‡åŒ–ç‰ˆ (626MB)
    case openaiLargeV3Turbo_626MB = "openai_whisper-large-v3-v20240930_626MB"
    
    // å‚™ç”¨
    case small = "small"
    
    var id: String { self.rawValue }
    
    var displayName: String {
        switch self {
        case .openaiLargeV3Turbo_626MB: return "OpenAI Turbo (626MB ğŸ‘‘)"
        case .small: return "Small (å‚™ç”¨)"
        }
    }
}

@MainActor
class STTService: ObservableObject {
    // MARK: - Published States
    @Published var isModelLoading = false
    @Published var statusMessage = "ç­‰å¾…é¸æ“‡éŠæˆ²..."
    
    @Published var currentModel: WhisperModel = {
        // ğŸ”¥ å¼·åˆ¶é–å®šç‚º OpenAI Turbo
        return .openaiLargeV3Turbo_626MB
    }()
    
    // MARK: - Internal Properties
    private var pipe: WhisperKit?
    private var audioRecorder: AVAudioRecorder?
    private var audioFilename: URL?
    private var currentKeywords: [String] = []
    
    // MARK: - æ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†
    
    func setupWhisper(keywords: [String]) async {
        self.currentKeywords = keywords
        
        if pipe != nil {
            print("âœ… æ¨¡å‹å¯¦é«”å·²å­˜åœ¨ï¼Œåƒ…æ›´æ–°é—œéµå­—")
            return
        }
        
        self.isModelLoading = true
        self.statusMessage = "ä¸‹è¼‰æ¨¡å‹: \(currentModel.displayName)..."
        
        do {
            print("ğŸš€ é–‹å§‹è¼‰å…¥æ¨¡å‹: \(currentModel.rawValue)")
            pipe = try await WhisperKit(model: currentModel.rawValue, download: true)
            
            // ğŸ”¥ [Warmup] ç†±èº«
            self.statusMessage = "æ­£åœ¨ç‚º A16 æ™¶ç‰‡æœ€ä½³åŒ– (ç†±èº«ä¸­)..."
            print("ğŸ”¥ é–‹å§‹æ¨¡å‹ç†±èº« (Warmup)...")
            try? await pipe?.transcribe(audioArray: [Float](repeating: 0, count: 16000))
            
            self.isModelLoading = false
            self.statusMessage = "é˜¿å¡å°±ç·’"
            print("âœ… æ¨¡å‹è¼‰å…¥èˆ‡ç†±èº«å®Œæˆ")
            
        } catch {
            self.statusMessage = "è¼‰å…¥å¤±æ•—: è«‹æª¢æŸ¥ç¶²è·¯æˆ–é‡å•Ÿ App"
            print("âŒ Whisper load error: \(error)")
            self.isModelLoading = false
        }
    }
    
    func switchModel(to newModel: WhisperModel) {
        if newModel == currentModel && pipe != nil { return }
        print("ğŸ”„ åˆ‡æ›æ¨¡å‹è‡³: \(newModel.rawValue)")
        currentModel = newModel
        UserDefaults.standard.set(newModel.rawValue, forKey: "selected_whisper_model")
        resetModel()
        statusMessage = "åˆ‡æ›è‡³ \(newModel.displayName)..."
    }
    
    func resetModel() {
        pipe = nil
        print("ğŸ—‘ æ¨¡å‹è¨˜æ†¶é«”å·²é‡‹æ”¾")
    }
    
    // MARK: - Audio Session Management
    
    @MainActor
    func configureAlwaysOnSession() {
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            print("âœ… [Audio] Session è¨­å®šç‚º Always-On PlayAndRecord")
        } catch {
            print("âŒ [Audio] Session è¨­å®šå¤±æ•—: \(error)")
        }
    }
    
    // MARK: - Recording Logic
    
    func startRecording() async {
        print("ğŸ™ï¸ æº–å‚™å•Ÿå‹•éŒ„éŸ³æµç¨‹...")
        
        await MainActor.run {
            configureAlwaysOnSession()
        }
        
        let recorder = await Task.detached(priority: .userInitiated) { () -> AVAudioRecorder? in
            let url = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0].appendingPathComponent("input.wav")
            
            let settings: [String: Any] = [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            do {
                return try AVAudioRecorder(url: url, settings: settings)
            } catch {
                print("âŒ éŒ„éŸ³åˆå§‹åŒ–å¤±æ•—: \(error)")
                return nil
            }
        }.value
        
        if let validRecorder = recorder {
            self.audioRecorder = validRecorder
            self.audioFilename = validRecorder.url
            
            if validRecorder.record() {
                print("ğŸ™ï¸ éŒ„éŸ³æ­£å¼é–‹å§‹")
            } else {
                print("âŒ å‘¼å« record() å¤±æ•—")
                self.statusMessage = "ç„¡æ³•å•Ÿå‹•éŒ„éŸ³"
            }
        } else {
            self.statusMessage = "éŒ„éŸ³å•Ÿå‹•å¤±æ•—"
        }
    }
    
    func stopAndTranscribe() async -> String? {
        // 1. åœæ­¢éŒ„éŸ³
        audioRecorder?.stop()
        audioRecorder = nil
        print("â¹ï¸ éŒ„éŸ³æ©Ÿå¯¦ä¾‹å·²éŠ·æ¯€")
        
        guard let pipe = pipe, let url = audioFilename else { return nil }
        
        // æª”æ¡ˆæª¢æŸ¥
        do {
            if !FileManager.default.fileExists(atPath: url.path) { return nil }
            let attr = try FileManager.default.attributesOfItem(atPath: url.path)
            if (attr[.size] as? UInt64 ?? 0) < 4096 { return nil }
        } catch { return nil }
        
        // ğŸ”¥ [Prompt] é˜²æ­¢è®Šè‹±æ–‡
        let promptText = "ç¹é«”ä¸­æ–‡æ¡ŒéŠå°è©±ã€‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚é—œéµè©ï¼š\(currentKeywords.joined(separator: ", "))"
        
        var promptTokens: [Int] = []
        if let tokenizer = pipe.tokenizer {
            promptTokens = tokenizer.encode(text: promptText)
                .filter { $0 < tokenizer.specialTokens.specialTokenBegin }
            print("â„¹ï¸ [Prompt] å•Ÿç”¨æˆåŠŸï¼ŒTokensæ•¸é‡: \(promptTokens.count)")
        }
        
        // ğŸ”¥ğŸ”¥ [æ¥µé™ä¿®æ­£] Turbo æ¨¡å‹è¶…ç´šéˆæ•è¨­å®š ğŸ”¥ğŸ”¥
        let options = DecodingOptions(
            language: "zh",
            temperature: 0.0,
            promptTokens: promptTokens,
            
            // 1. å¼·åˆ¶å¿½ç•¥ä¿¡å¿ƒåˆ†æ•¸ (è¨­ç‚º -100.0)
            // åªè¦æœ‰è²éŸ³ï¼Œä¸ç®¡æ¨¡å‹å¤šæ²’æŠŠæ¡ï¼Œéƒ½è¦åå‡ºæ–‡å­—
            compressionRatioThreshold: 2.4,
            logProbThreshold: -100.0,
            
            // 2. æ¥µé™éœéŸ³é–€æª»
            // é™¤é 99.5% ç¢ºå®šæ˜¯éœéŸ³ï¼Œå¦å‰‡éƒ½è¦–ç‚ºæœ‰èªªè©±
            noSpeechThreshold: 0.995,
            
            // 3. é¿å…ç„¡çª®è¿´åœˆ
        )
        
        print("ğŸ“ é–‹å§‹è¾¨è­˜ (Model: \(currentModel.displayName))")
        
        do {
            let result = try await pipe.transcribe(audioPath: url.path, decodeOptions: options)
            let text = result.first?.text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
            
            print("ğŸ“ [Whisper è¾¨è­˜çµæœ]: \(text ?? "nil")")
            
            if let t = text, (t.isEmpty || t == "you" || t.lowercased().contains("thank you")) {
                 return nil
            }
            return (text?.isEmpty ?? true) ? nil : text
        } catch {
            print("âŒ è¾¨è­˜å¤±æ•—: \(error)")
            return nil
        }
    }
}
