import Foundation
import AVFoundation
import WhisperKit
import Combine

// MARK: - æ¨¡å‹å®šç¾©
enum WhisperModel: String, CaseIterable, Identifiable {
    case distilLargeV3 = "distil-large-v3"
    case largeV3 = "large-v3"
    case medium = "medium"
    case base = "base"
    case small = "small"
    
    var id: String { self.rawValue }
    
    var displayName: String {
        switch self {
        case .distilLargeV3: return "Distil Large V3 (æ¨è–¦)"
        case .largeV3: return "Large V3 (ç²¾æº–/æ…¢)"
        case .medium: return "Medium (å¹³è¡¡)"
        case .base: return "Base (å¿«é€Ÿ)"
        case .small: return "Small (æ¥µé€Ÿ)"
        }
    }
}

@MainActor
class STTService: ObservableObject {
    // MARK: - Published States
    @Published var isModelLoading = false
    @Published var statusMessage = "ç­‰å¾…é¸æ“‡éŠæˆ²..."
    
    @Published var currentModel: WhisperModel = {
        if let saved = UserDefaults.standard.string(forKey: "selected_whisper_model"),
           let model = WhisperModel(rawValue: saved) {
            return model
        }
        return .distilLargeV3
    }()
    
    // MARK: - Internal Properties
    private var pipe: WhisperKit?
    private var audioRecorder: AVAudioRecorder?
    private var audioFilename: URL?
    private var currentKeywords: [String] = []
    
    // MARK: - æ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†
    
    func setupWhisper(keywords: [String]) async {
        self.currentKeywords = keywords
        
        if pipe != nil {
            print("âœ… æ¨¡å‹å¯¦é«”å·²å­˜åœ¨ï¼Œåƒ…æ›´æ–°é—œéµå­—")
            return
        }
        
        self.isModelLoading = true
        self.statusMessage = "ä¸‹è¼‰æ¨¡å‹: \(currentModel.rawValue)..."
        
        do {
            print("ğŸš€ é–‹å§‹è¼‰å…¥æ¨¡å‹: \(currentModel.rawValue)")
            pipe = try await WhisperKit(model: currentModel.rawValue, download: true)
            self.isModelLoading = false
            self.statusMessage = "é˜¿å¡å°±ç·’ (\(currentModel.rawValue))"
            print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
        } catch {
            self.statusMessage = "è¼‰å…¥å¤±æ•—: \(error.localizedDescription)"
            print("âŒ Whisper load error: \(error)")
            self.isModelLoading = false
        }
    }
    
    func switchModel(to newModel: WhisperModel) {
        if newModel == currentModel && pipe != nil { return }
        print("ğŸ”„ åˆ‡æ›æ¨¡å‹è‡³: \(newModel.rawValue)")
        currentModel = newModel
        UserDefaults.standard.set(newModel.rawValue, forKey: "selected_whisper_model")
        resetModel()
        statusMessage = "å·²åˆ‡æ›è‡³ \(newModel.rawValue)ï¼Œæ­£åœ¨æº–å‚™ä¸‹è¼‰..."
    }
    
    func resetModel() {
        pipe = nil
        print("ğŸ—‘ æ¨¡å‹è¨˜æ†¶é«”å·²é‡‹æ”¾")
    }
    
    // MARK: - éŸ³è¨Š Session ç®¡ç† (Helper Methods)
    
    // ğŸ”¥ [é—œéµä¿®æ”¹] æ¨™è¨˜ç‚º nonisolatedï¼Œå…è¨±å¾èƒŒæ™¯ Task å‘¼å«
    nonisolated func activateAudioSession() {
        do {
            let session = AVAudioSession.sharedInstance()
            // ä½¿ç”¨ .playAndRecord ä¸¦é–‹å•Ÿ mixWithOthersï¼Œæ¸›å°‘å°ç³»çµ±çš„è¡æ“Š
            try session.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth, .mixWithOthers])
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            print("ğŸŸ¢ Audio Session å·²å•Ÿå‹• (Background)")
        } catch {
            print("âŒ å•Ÿå‹• Session å¤±æ•—: \(error.localizedDescription)")
        }
    }
    
    // ğŸ”¥ [é—œéµä¿®æ”¹] æ¨™è¨˜ç‚º nonisolated
    nonisolated func deactivateAudioSession() {
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
            print("ğŸ”´ Audio Session å·²é‡‹æ”¾ (Background)")
        } catch {
            print("âš ï¸ é‡‹æ”¾ Session å¤±æ•—: \(error)")
        }
    }
    
    // MARK: - éŒ„éŸ³æ§åˆ¶ (ğŸ”¥ è§£æ±º UI å¡æ­»çš„æ ¸å¿ƒ)
    
    // 1. æ”¹ç‚º asyncï¼Œè®“ UI åŸ·è¡Œç·’å¯ä»¥ç¹¼çºŒåˆ·æ–°
    func startRecording() async {
        print("ğŸ™ï¸ æº–å‚™å•Ÿå‹•éŒ„éŸ³æµç¨‹...")
        
        // 2. å°‡ã€Œè€—æ™‚ 3~5ç§’ã€çš„ç¡¬é«”åˆå§‹åŒ–å·¥ä½œä¸Ÿåˆ°èƒŒæ™¯åŸ·è¡Œç·’ (Detached Task)
        let recorder = await Task.detached(priority: .userInitiated) { [weak self] () -> AVAudioRecorder? in
            guard let self = self else { return nil }
            
            // A. é€™è£¡åŸ·è¡Œæœ€è€—æ™‚çš„ Session å•Ÿå‹• (åŸæœ¬å¡æ­» UI çš„å…‡æ‰‹)
            self.activateAudioSession()
            
            // B. æº–å‚™è·¯å¾‘èˆ‡è¨­å®š
            let url = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0].appendingPathComponent("input.wav")
            
            let settings: [String: Any] = [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            // C. åˆå§‹åŒ– Recorder
            do {
                let newRecorder = try AVAudioRecorder(url: url, settings: settings)
                // é€™è£¡åªåšåˆå§‹åŒ–ï¼Œä¸å‘¼å« record()ï¼Œå› ç‚º record() æœ€å¥½å›ä¸»ç·šç¨‹å‘¼å«æ¯”è¼ƒä¿éšª
                return newRecorder
            } catch {
                print("âŒ éŒ„éŸ³åˆå§‹åŒ–å¤±æ•—: \(error)")
                return nil
            }
        }.value
        
        // 3. å›åˆ° Main Actor (ä¸»åŸ·è¡Œç·’) æ›´æ–°ç‹€æ…‹ä¸¦é–‹å§‹éŒ„éŸ³
        if let validRecorder = recorder {
            self.audioRecorder = validRecorder
            self.audioFilename = validRecorder.url
            
            let success = validRecorder.record()
            if success {
                print("ğŸ™ï¸ éŒ„éŸ³æ­£å¼é–‹å§‹ (UI æ‡‰å·²æ›´æ–°)")
            } else {
                print("âŒ record() å›å‚³å¤±æ•—")
                self.statusMessage = "ç„¡æ³•å•Ÿå‹•éŒ„éŸ³"
            }
        } else {
            self.statusMessage = "éŒ„éŸ³å•Ÿå‹•å¤±æ•—"
        }
    }
    
    func stopAndTranscribe() async -> String? {
        audioRecorder?.stop()
        print("â¹ï¸ åœæ­¢éŒ„éŸ³")
        
        // 4. éŒ„éŸ³çµæŸå¾Œé‡‹æ”¾è³‡æº (èƒŒæ™¯åŸ·è¡Œï¼Œé¿å…å¡é “)
        Task.detached {
            self.deactivateAudioSession()
        }
        
        guard let pipe = pipe, let url = audioFilename else { return nil }
        
        // æª”æ¡ˆæª¢æŸ¥ (é˜²å´©æ½°)
        do {
            if !FileManager.default.fileExists(atPath: url.path) {
                print("âš ï¸ [STT] éŒ„éŸ³æª”ä¸å­˜åœ¨")
                return nil
            }
            
            let attr = try FileManager.default.attributesOfItem(atPath: url.path)
            let fileSize = attr[.size] as? UInt64 ?? 0
            if fileSize < 4096 { // å°æ–¼ 4KB è¦–ç‚ºç„¡æ•ˆ
                print("âš ï¸ [STT] éŒ„éŸ³æª”å¤ªçŸ­ (\(fileSize) bytes)ï¼Œè·³éè¾¨è­˜")
                return nil
            }
        } catch {
            print("âš ï¸ [STT] æª”æ¡ˆæª¢æŸ¥å¤±æ•—: \(error)")
            return nil
        }
        
        let promptText = "ç¹é«”ä¸­æ–‡æ¡ŒéŠå°è©±ã€‚é—œéµè©ï¼š\(currentKeywords.joined(separator: ", "))"
        
        // DecodingOptions
        let options = DecodingOptions(language: "zh")
        
        let result = try? await pipe.transcribe(audioPath: url.path, decodeOptions: options)
        let text = result?.first?.text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
        
        // ğŸ”¥ [Debug] å°å‡ºè¾¨è­˜çµæœ
        print("ğŸ“ [Whisper è¾¨è­˜çµæœ]: \(text ?? "nil (ç„¡è²)")")
        
        return (text?.isEmpty ?? true) ? nil : text
    }
}
