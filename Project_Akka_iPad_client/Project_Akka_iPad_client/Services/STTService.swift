import Foundation
import AVFoundation
import WhisperKit
import Combine

// MARK: - æ¨¡å‹å®šç¾©
enum WhisperModel: String, CaseIterable, Identifiable {
    case openaiLargeV3Turbo = "openai_whisper-large-v3-v20240930_turbo_632MB"
    case largeV3Turbo600MB = "distil-whisper_distil-large-v3_turbo_600MB"
    case base = "base"
    case small = "small"
    
    var id: String { self.rawValue }
    
    var displayName: String {
        switch self {
        case .largeV3Turbo600MB: return "Large V3 Turbo (600MB ğŸ‘‘æ¨è–¦)"
        case .openaiLargeV3Turbo: return "Large V3 Turbo (632MB)"
        case .base: return "Base (å¿«é€Ÿ)"
        case .small: return "Small (æ¥µé€Ÿ)"
        }
    }
}

@MainActor
class STTService: ObservableObject {
    // MARK: - Published States
    @Published var isModelLoading = false
    @Published var statusMessage = "ç­‰å¾…é¸æ“‡éŠæˆ²..."
    
    @Published var currentModel: WhisperModel = {
        if let saved = UserDefaults.standard.string(forKey: "selected_whisper_model"),
           let model = WhisperModel(rawValue: saved) {
            return model
        }
        return .largeV3Turbo600MB
    }()
    
    // MARK: - Internal Properties
    private var pipe: WhisperKit?
    private var audioRecorder: AVAudioRecorder?
    private var audioFilename: URL?
    private var currentKeywords: [String] = []
    
    // MARK: - æ¨¡å‹ç”Ÿå‘½é€±æœŸç®¡ç†
    
    func setupWhisper(keywords: [String]) async {
            self.currentKeywords = keywords
            
            if pipe != nil {
                print("âœ… æ¨¡å‹å¯¦é«”å·²å­˜åœ¨ï¼Œåƒ…æ›´æ–°é—œéµå­—")
                return
            }
            
            self.isModelLoading = true
            self.statusMessage = "ä¸‹è¼‰æ¨¡å‹: \(currentModel.displayName)..."
            
            do {
                print("ğŸš€ é–‹å§‹è¼‰å…¥æ¨¡å‹: \(currentModel.rawValue)")
                pipe = try await WhisperKit(model: currentModel.rawValue, download: true)
                
                // ğŸ”¥ [æ–°å¢] è‡ªå‹•ç†±èº« (Warmup)
                // åœ¨ä½¿ç”¨è€…é‚„æ²’é–‹å§‹èªªè©±å‰ï¼Œå…ˆå¼·åˆ¶åŸ·è¡Œä¸€æ¬¡ç©ºè¾¨è­˜ï¼Œè§¸ç™¼ ANE ç·¨è­¯
                self.statusMessage = "æ­£åœ¨ç‚º A16 æ™¶ç‰‡æœ€ä½³åŒ– (ç†±èº«ä¸­)..."
                print("ğŸ”¥ é–‹å§‹æ¨¡å‹ç†±èº« (Warmup)...")
                
                // å»ºç«‹ä¸€å€‹æ¥µçŸ­çš„éœéŸ³éŸ³è¨Šé€²è¡Œç†±èº«
                // é€™è£¡æˆ‘å€‘ç°¡å–®åœ°è®“å®ƒ transcribe ä¸€å€‹ç©ºè·¯å¾‘æˆ–æ˜¯æ¥µçŸ­çš„ dummy æª”æ¡ˆï¼Œ
                // ä½†æœ€ç°¡å–®çš„æ–¹æ³•æ˜¯è®“å®ƒè·‘ä¸€æ¬¡ç©ºçš„ decode (å¦‚æœ WhisperKit æ”¯æ´)
                // æˆ–æ˜¯ç›´æ¥å‘Šè¨´ä½¿ç”¨è€…ã€Œæº–å‚™å®Œæˆã€ä½†å¿ƒè£¡çŸ¥é“ç¬¬ä¸€æ¬¡æœƒæ…¢ã€‚
                //
                // æ¯”è¼ƒæ­£è¦çš„åšæ³•æ˜¯ï¼š
                try? await pipe?.transcribe(audioArray: [Float](repeating: 0, count: 16000)) // 1ç§’éœéŸ³
                
                self.isModelLoading = false
                self.statusMessage = "é˜¿å¡å°±ç·’"
                print("âœ… æ¨¡å‹è¼‰å…¥èˆ‡ç†±èº«å®Œæˆ")
                
            } catch {
                self.statusMessage = "è¼‰å…¥å¤±æ•—: \(error.localizedDescription)"
                print("âŒ Whisper load error: \(error)")
                self.isModelLoading = false
            }
        }
    
    func switchModel(to newModel: WhisperModel) {
        if newModel == currentModel && pipe != nil { return }
        print("ğŸ”„ åˆ‡æ›æ¨¡å‹è‡³: \(newModel.rawValue)")
        currentModel = newModel
        UserDefaults.standard.set(newModel.rawValue, forKey: "selected_whisper_model")
        resetModel()
        statusMessage = "å·²åˆ‡æ›è‡³ \(newModel.rawValue)ï¼Œæ­£åœ¨æº–å‚™ä¸‹è¼‰..."
    }
    
    func resetModel() {
        pipe = nil
        print("ğŸ—‘ æ¨¡å‹è¨˜æ†¶é«”å·²é‡‹æ”¾")
    }
    
    // MARK: - Audio Session Management (éŒ„éŸ³å°ˆç”¨)
        
        /// ğŸ”¥ [ä¿®æ”¹] é…ç½®å¸¸é§å‹ Session
        /// ç­–ç•¥ï¼šè¨­å®šç‚º PlayAndRecord + DefaultToSpeakerï¼ŒåŒæ™‚æ»¿è¶³éŒ„éŸ³èˆ‡ TTS æ“´éŸ³éœ€æ±‚
        @MainActor
        func configureAlwaysOnSession() {
            do {
                let session = AVAudioSession.sharedInstance()
                try session.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
                try session.setActive(true, options: .notifyOthersOnDeactivation)
                print("âœ… [Audio] Session è¨­å®šç‚º Always-On PlayAndRecord")
            } catch {
                print("âŒ [Audio] Session è¨­å®šå¤±æ•—: \(error)")
            }
        }

        /// ğŸ”¥ [ä¿®æ”¹] åœç”¨åŠŸèƒ½æ”¹ç‚ºç©ºå¯¦ä½œ
        /// ç­–ç•¥ï¼šæ°¸é ä¸é—œé–‰ Sessionï¼Œé¿å…ç¡¬é«”é‡å•Ÿå°è‡´çš„ Crash
        func deactivateSession() async {
            // No-op: ä¿æŒ Session é–‹å•Ÿ
            print("ğŸ›¡ï¸ [Audio] å¿½ç•¥åœç”¨è«‹æ±‚ (Always-On Strategy)")
        }
    
    
    // MARK: - Recording Logic
    
    func startRecording() async {
        print("ğŸ™ï¸ æº–å‚™å•Ÿå‹•éŒ„éŸ³æµç¨‹...")
        
        // ğŸ”§ [ä¿®æ­£] ç›´æ¥åœ¨èƒŒæ™¯åŸ·è¡Œ async å‡½æ•¸ï¼Œä¸å†ä½¿ç”¨ detached task ä»¥é¿å… actor isolation å•é¡Œ
        // 1. å•Ÿå‹• Session (async)
        await MainActor.run {
                    configureAlwaysOnSession()
                }
        
        let recorder = await Task.detached(priority: .userInitiated) { () -> AVAudioRecorder? in
            let url = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0].appendingPathComponent("input.wav")
            
            // 2. è¨­å®šéŒ„éŸ³åƒæ•¸ (Whisper åå¥½ 16kHz)
            let settings: [String: Any] = [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            do {
                let newRecorder = try AVAudioRecorder(url: url, settings: settings)
                return newRecorder
            } catch {
                print("âŒ éŒ„éŸ³åˆå§‹åŒ–å¤±æ•—: \(error)")
                return nil
            }
        }.value
        
        if let validRecorder = recorder {
            self.audioRecorder = validRecorder
            self.audioFilename = validRecorder.url
            
            // record() å»ºè­°åœ¨ Main Thread æˆ–ç”± Recorder å¯¦ä¾‹æ‰€åœ¨çš„ Context å‘¼å«
            if validRecorder.record() {
                print("ğŸ™ï¸ éŒ„éŸ³æ­£å¼é–‹å§‹")
            } else {
                print("âŒ å‘¼å« record() å¤±æ•—")
                self.statusMessage = "ç„¡æ³•å•Ÿå‹•éŒ„éŸ³"
            }
        } else {
            self.statusMessage = "éŒ„éŸ³å•Ÿå‹•å¤±æ•—"
        }
    }
    
    func stopAndTranscribe() async -> String? {
            // 1. åœæ­¢éŒ„éŸ³
            audioRecorder?.stop()
            audioRecorder = nil // é‡‹æ”¾è³‡æº
            print("â¹ï¸ éŒ„éŸ³æ©Ÿå¯¦ä¾‹å·²éŠ·æ¯€")
            
            guard let pipe = pipe, let url = audioFilename else { return nil }
            
            // æª”æ¡ˆæª¢æŸ¥
            do {
                if !FileManager.default.fileExists(atPath: url.path) { return nil }
                let attr = try FileManager.default.attributesOfItem(atPath: url.path)
                if (attr[.size] as? UInt64 ?? 0) < 4096 { return nil }
            } catch { return nil }
            
            // 2. æº–å‚™æç¤ºè© (Prompt)
            let promptText = "ç¹é«”ä¸­æ–‡æ¡ŒéŠå°è©±ã€‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚é—œéµè©ï¼š\(currentKeywords.joined(separator: ", "))"
            
            // ğŸ”¥ [ä¿®æ­£] æ‰‹å‹•å°‡æ–‡å­—è½‰ç‚º Token
            // WhisperKit ä¸æ¥å— String é¡å‹çš„ promptï¼Œå¿…é ˆæ‰‹å‹• Tokenize
            var promptTokens: [Int] = []
            if let tokenizer = pipe.tokenizer {
                // éæ¿¾æ‰ç‰¹æ®Šå­—å…ƒï¼Œåªä¿ç•™æ–‡å­— Token
                promptTokens = tokenizer.encode(text: promptText)
                    .filter { $0 < tokenizer.specialTokens.specialTokenBegin }
            }
            
            // 3. è¨­å®šè§£ç¢¼é¸é …
            // language: å¼·åˆ¶è¨­å®šç‚ºä¸­æ–‡ "zh"
            // temperature: 0.0 ä»£è¡¨æœ€ç²¾æº–ï¼Œä¸åšéš¨æ©Ÿè¯æƒ³
            // promptTokens: é€™æ˜¯æˆ‘å€‘å‰›è½‰å¥½çš„ Token é™£åˆ—
            let options = DecodingOptions(
                language: "zh",
                temperature: 0.0,
                promptTokens: promptTokens // ğŸ‘ˆ é€™è£¡åŸæœ¬å¯« prompt: promptText æœƒå ±éŒ¯ï¼Œæ”¹ç”¨é€™å€‹
            )
            
            print("ğŸ“ é–‹å§‹è¾¨è­˜ (Prompt: \(promptText.prefix(10))...)")
            
            do {
                let result = try await pipe.transcribe(audioPath: url.path, decodeOptions: options)
                let text = result.first?.text.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
                
                print("ğŸ“ [Whisper è¾¨è­˜çµæœ]: \(text ?? "nil")")
                
                // éæ¿¾å¹»è¦º
                if let t = text, (t.isEmpty || t == "you" || t.lowercased().contains("thank you")) {
                     return nil
                }
                
                return (text?.isEmpty ?? true) ? nil : text
            } catch {
                print("âŒ è¾¨è­˜å¤±æ•—: \(error)")
                return nil
            }
        }
}
